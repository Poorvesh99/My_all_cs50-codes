Times:

10 simulations: 0m0.035s (record time using 0m0.000s format)
100 simulations: 0m0.027s (record time using 0m0.000s format)
1000 simulations: 0m0.049s (record time using 0m0.000s format)
10000 simulations: 0m0.097s (record time using 0m0.000s format)
100000 simulations: 0m0.841s (record time using 0m0.000s format)
1000000 simulations: 0m8.322s (record time using 0m0.000s format)

Questions:

Which predictions, if any, proved incorrect as you increased the number of simulations?: pretty much they remain same
except for start when there was less simulation

Suppose you're charged a fee for each second of compute time your program uses.
After how many simulations would you call the predictions "good enough"?: i would stop rather at 10000 simulation
as it every other from there give just similar result